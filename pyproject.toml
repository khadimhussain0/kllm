[project]
name = "kllm"
version = "0.1.0"
description = "Fine-tune LLMs with LoRA/QLoRA on consumer hardware"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.12"
dependencies = [
    "wandb>=0.18.0",
    "tensorboard>=2.18.0",
    "typer>=0.12.0",
    "rich>=13.9.0",
    "pyyaml>=6.0.0",
    "pandas>=2.2.0",
    "datasets>=3.0.0",
]

[project.optional-dependencies]
dev = ["ruff>=0.7.0", "pytest>=8.0.0"]
eval = ["lm-eval>=0.4.0"]

# ML dependencies - install manually per SETUP.md due to CUDA version requirements
# These are listed for reference only, do not install via pip install .[ml]
# ml = [
#     "torch>=2.9.0",
#     "vllm>=0.15.0",
#     "transformers==4.57.3",
#     "unsloth",
#     "unsloth_zoo",
#     "bitsandbytes",
#     "trl",
#     "peft",
# ]

[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B"]
ignore = ["E501"]

[tool.ruff.format]
quote-style = "double"
