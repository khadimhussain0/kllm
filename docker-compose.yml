services:
  kllm:
    build: .
    image: kllm:latest
    container_name: kllm
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - WANDB_API_KEY=${WANDB_API_KEY}
      - HF_TOKEN=${HF_TOKEN}
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - .:/app
      - ~/.cache/huggingface:/workspace/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    stdin_open: true
    tty: true

  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: kllm-tensorboard
    volumes:
      - ./results:/app/results
    ports:
      - "6006:6006"
    command: tensorboard --logdir=/app/results --host=0.0.0.0 --port=6006
